---
title: "Assigment - Naive Bayes DIY"
author:
  - Minh Le Ngoc Nguyen - Author
  - Ha Trang Nguyen - Reviewer
date: "03/10/2022"
output:
   html_notebook:
    toc: true
    toc_depth: 2
---

```{r}
library(tidyverse)
library(tm)
library(caret)
library(wordcloud)
library(e1071)
library(SnowballC)
```

## Business Understanding
The purpose is using Naive Bayes model to identify fake news in the chosen data set. 

## Data Understanding
Reading data
```{r}
url <- https://raw.githubusercontent.com/HAN-M3DM-Data-Mining/data-mining-s2y2122-LilSagi/master/datasets/NB-fakenews.csv 
rawdata <- read_csv(url) 
View(rawdata)
```


Listing headings
```{r}
head(rawdata)
```

Changing character to factor
```{r}
rawdata$id -> NULL 
rawdata$title -> NULL 
rawdata$author -> NULL 
rawdata <- rawdata %>% relocate(label, .before = text)
rawdata <- mutate(label = recode(label,"0"= "news", "1"= "fake")) 
rawdata$label <- rawdata$label %>% factor 
class(rawdata$label)
```

Visually inspect the data 
```{r}
fake <- rawdata %>% filter(label == "fake")
news <- rawdata %>% filter(label == "news")

rawdata$text <- gsub("the","",as.character(rawdata$text))

wordcloud(fake, max.words = 20, scale = c(4, 0.8), colors=  c("indianred1","indianred2","indianred3","indianred"))
wordcloud(news, max.words = 20, scale = c(4, 0.8), colors=  c("lightsteelblue1","lightsteelblue2","lightsteelblue3","lightsteelblue"))

gc()
```

## Data Preparation

```{r}
rawCorpus <- Corpus(VectorSource(rawdata$text))
inspect(rawCorpus[1:3])

cleanCorpus <- rawCorpus %>% tm_map(tolower) %>% tm_map(removeNumbers)
cleanCorpus <- cleanCorpus %>% tm_map(tolower) %>% tm_map(removeWords, stopwords()) %>% 
cleanCorpus <- cleanCorpus %>% tm_map(stripwhitespace) 
cleanCorpus <- cleanCorpus %>% tm_map(stemDocument)


#Inspect how Corpus works
tibble(Raw = rawCorpus$content[1:3], Clean = cleanCorpus$content[1:3])
```

```{r}
cleanDTM <- cleanCorpus %>% DocumentTermMatrix

inspect(cleanDTM)
```

```{r}
set.seed(1234)
trainIndex <- createDataPartition(label, p = .75, 
                                  list = FALSE, 
                                  times = 1)
head(trainIndex)
```
```{r}
# Apply split indices to DF
trainDF <- rawdata[trainIndex, ]
testDF <- rawdata[-trainIndex, ]
```

```{r}
# Apply split indices to Corpus 
trainCorpus <- cleanCorpus[trainIndex]
testCorpus <- cleanCorpus[trainIndex] 

# Apply split indices to DTM 
trainDTM <- cleanDTM[trainIndex, ]
testDTM <- cleanDTM[-trainIndex, ]
```

```{r}
freqWords <- trainDTM %>% findFreqTerms(50)

trainDTM <-  DocumentTermMatrix(trainCorpus, list(dictionary = freqWords))

testDTM <-  DocumentTermMatrix(testCorpus, list(dictionary = freqWords) 
inspect(trainDTM)
inspect(testDTM)
```

```{r}
convert_counts <- function(x) {
  x <- ifelse(x > 0, 1, 0) %>% factor(levels = c(0,1), labels = c("No", "Yes"))
}

nColsDTM <- dim(trainDTM)[2]
trainDTM <- apply(trainDTM, MARGIN = 2, convert.counts) 
testDTM <- apply(testDTM, MARGIN = 2, convert.counts) 

head(trainDTM[,1:10])
```

## Modeling
```{r}
nbayesModel <-  naiveBayes(trainDTM, trainDF$label, laplace = 1)
predVec <- predict(nbayesModel, testDTM)
confusionMatrix(predVec, testDF$label, positive = "fake", dnn = c("Prediction", "True"))
```

## Evaluation and Deployment
The model gives the result of 74 percent of accuracy level. I tried to remove unnecessary words and lower the frequency of words but it seems not to be helpful. 

Hence, the reviewer may add suggestion to improve the model. 

